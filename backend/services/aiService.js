// è¿™ä¸ªæ–‡ä»¶åŒ…å«ï¼š
// - AIServiceFactory (å·¥åŽ‚ç±»)
// - BaseAIService (åŸºç±»)
// - ClaudeService (Claudeå®žçŽ°)
// - DeepSeekService (DeepSeekå®žçŽ°)
// - OpenAIService (OpenAIå®žçŽ°)
// - GeminiService (Geminiå®žçŽ°)
// - QwenService (é€šä¹‰åƒé—®å®žçŽ°)
// - GLMService (æ™ºè°±GLMå®žçŽ°)
// - AutoTestService (ä¸»æœåŠ¡ç±»)

// æˆ‘ä¹‹å‰ç”Ÿæˆçš„ "å¤šAIå¼•æ“Žæ”¯æŒçš„è‡ªåŠ¨åŒ–æµ‹è¯•å¹³å°" ä»£ç 
// å®Œæ•´å†…å®¹å°±æ”¾åœ¨è¿™ä¸ªæ–‡ä»¶é‡Œ

// ============================================
// AI æœåŠ¡æŠ½è±¡å±‚ - æ”¯æŒå¤šç§AIå¼•æ“Ž
// ============================================

/**
 * AIæœåŠ¡å·¥åŽ‚ç±»
 * ç»Ÿä¸€çš„æŽ¥å£ï¼Œæ”¯æŒåˆ‡æ¢ä¸åŒçš„AIæä¾›å•†
 */
class AIServiceFactory {
  static create(provider, config) {
    switch (provider.toLowerCase()) {
      case 'claude':
        return new ClaudeService(config);
      case 'deepseek':
        return new DeepSeekService(config);
      case 'openai':
        return new OpenAIService(config);
      case 'gemini':
        return new GeminiService(config);
      case 'qwen':
        return new QwenService(config);
      case 'glm':
        return new GLMService(config);
      default:
        throw new Error(`ä¸æ”¯æŒçš„AIæä¾›å•†: ${provider}`);
    }
  }
}

/**
 * AIæœåŠ¡åŸºç±» - å®šä¹‰ç»Ÿä¸€æŽ¥å£
 */
class BaseAIService {
  constructor(config) {
    this.config = config;
    this.apiKey = config.apiKey;
    this.baseURL = config.baseURL;
    this.model = config.model;
  }

  // å¿…é¡»å®žçŽ°çš„æ–¹æ³•
  async analyze(config, prompt) {
    throw new Error('å­ç±»å¿…é¡»å®žçŽ° analyze æ–¹æ³•');
  }

  async generateTestCases(analysis, prompt) {
    throw new Error('å­ç±»å¿…é¡»å®žçŽ° generateTestCases æ–¹æ³•');
  }

  async generateReport(results, prompt) {
    throw new Error('å­ç±»å¿…é¡»å®žçŽ° generateReport æ–¹æ³•');
  }

  // é€šç”¨æ–¹æ³•
  fillTemplate(template, vars) {
    let result = template;
    for (const [key, value] of Object.entries(vars)) {
      result = result.replace(new RegExp(`{${key}}`, 'g'), value);
    }
    return result;
  }

  parseJSON(text) {
    // å°è¯•æå–JSONï¼ˆå¤„ç†AIå¯èƒ½è¿”å›žçš„Markdownä»£ç å—ï¼‰
    const jsonMatch = text.match(/```json\s*([\s\S]*?)\s*```/) ||
                      text.match(/```\s*([\s\S]*?)\s*```/) ||
                      [null, text];

    try {
      return JSON.parse(jsonMatch[1] || text);
    } catch (error) {
      console.error('JSONè§£æžå¤±è´¥:', error);
      return { error: 'JSONè§£æžå¤±è´¥', raw: text };
    }
  }
}

// ============================================
// Claude AI æœåŠ¡å®žçŽ°
// ============================================
class ClaudeService extends BaseAIService {
  constructor(config) {
    super(config);
    const Anthropic = require('@anthropic-ai/sdk');
    this.client = new Anthropic({
      apiKey: this.apiKey
    });
    this.model = this.model || 'claude-sonnet-4-20250514';
  }

  async analyze(testConfig, promptTemplate) {
    const prompt = this.fillTemplate(promptTemplate, testConfig);

    const message = await this.client.messages.create({
      model: this.model,
      max_tokens: 4000,
      messages: [{
        role: 'user',
        content: prompt
      }]
    });

    return this.parseJSON(message.content[0].text);
  }

  async generateTestCases(analysis, promptTemplate) {
    const message = await this.client.messages.create({
      model: this.model,
      max_tokens: 4000,
      messages: [{
        role: 'user',
        content: `${promptTemplate}\n\nåˆ†æžç»“æžœ:\n${JSON.stringify(analysis, null, 2)}`
      }]
    });

    return this.parseJSON(message.content[0].text);
  }

  async generateReport(results, promptTemplate) {
    const message = await this.client.messages.create({
      model: this.model,
      max_tokens: 4000,
      messages: [{
        role: 'user',
        content: `${promptTemplate}\n\næµ‹è¯•ç»“æžœ:\n${JSON.stringify(results, null, 2)}`
      }]
    });

    return message.content[0].text;
  }
}

// ============================================
// DeepSeek AI æœåŠ¡å®žçŽ°
// ============================================
class DeepSeekService extends BaseAIService {
  constructor(config) {
    super(config);
    this.baseURL = this.baseURL || 'https://api.deepseek.com/v1';
    this.model = this.model || 'deepseek-chat';
  }

  async makeRequest(messages) {
    const response = await fetch(`${this.baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        model: this.model,
        messages: messages,
        temperature: 0.7,
        max_tokens: 4000
      })
    });

    if (!response.ok) {
      const error = await response.text();
      throw new Error(`DeepSeek API é”™è¯¯: ${error}`);
    }

    const data = await response.json();
    return data.choices[0].message.content;
  }

  async analyze(testConfig, promptTemplate) {
    const prompt = this.fillTemplate(promptTemplate, testConfig);

    const content = await this.makeRequest([
      {
        role: 'system',
        content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æµ‹è¯•å·¥ç¨‹å¸ˆï¼Œæ“…é•¿åˆ†æžWebé¡µé¢å¹¶è®¾è®¡æµ‹è¯•ç”¨ä¾‹ã€‚'
      },
      {
        role: 'user',
        content: prompt
      }
    ]);

    return this.parseJSON(content);
  }

  async generateTestCases(analysis, promptTemplate) {
    const content = await this.makeRequest([
      {
        role: 'system',
        content: 'ä½ æ˜¯æµ‹è¯•ç”¨ä¾‹è®¾è®¡ä¸“å®¶ï¼Œèƒ½å¤Ÿè®¾è®¡å…¨é¢çš„æµ‹è¯•åœºæ™¯ã€‚'
      },
      {
        role: 'user',
        content: `${promptTemplate}\n\nåˆ†æžç»“æžœ:\n${JSON.stringify(analysis, null, 2)}`
      }
    ]);

    return this.parseJSON(content);
  }

  async generateReport(results, promptTemplate) {
    const content = await this.makeRequest([
      {
        role: 'system',
        content: 'ä½ æ˜¯æµ‹è¯•æŠ¥å‘Šä¸“å®¶ï¼Œæ“…é•¿ç”Ÿæˆä¸“ä¸šçš„æµ‹è¯•æŠ¥å‘Šã€‚'
      },
      {
        role: 'user',
        content: `${promptTemplate}\n\næµ‹è¯•ç»“æžœ:\n${JSON.stringify(results, null, 2)}`
      }
    ]);

    return content;
  }
}

// ============================================
// OpenAI (GPT) æœåŠ¡å®žçŽ°
// ============================================
class OpenAIService extends BaseAIService {
  constructor(config) {
    super(config);
    const OpenAI = require('openai');
    this.client = new OpenAI({
      apiKey: this.apiKey,
      baseURL: this.baseURL || 'https://api.openai.com/v1'
    });
    this.model = this.model || 'gpt-4-turbo';
  }

  async analyze(testConfig, promptTemplate) {
    const prompt = this.fillTemplate(promptTemplate, testConfig);

    const completion = await this.client.chat.completions.create({
      model: this.model,
      messages: [
        {
          role: 'system',
          content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æµ‹è¯•å·¥ç¨‹å¸ˆã€‚'
        },
        {
          role: 'user',
          content: prompt
        }
      ],
      temperature: 0.7,
      max_tokens: 4000
    });

    return this.parseJSON(completion.choices[0].message.content);
  }

  async generateTestCases(analysis, promptTemplate) {
    const completion = await this.client.chat.completions.create({
      model: this.model,
      messages: [
        {
          role: 'system',
          content: 'ä½ æ˜¯æµ‹è¯•ç”¨ä¾‹è®¾è®¡ä¸“å®¶ã€‚'
        },
        {
          role: 'user',
          content: `${promptTemplate}\n\n${JSON.stringify(analysis, null, 2)}`
        }
      ],
      max_tokens: 4000
    });

    return this.parseJSON(completion.choices[0].message.content);
  }

  async generateReport(results, promptTemplate) {
    const completion = await this.client.chat.completions.create({
      model: this.model,
      messages: [
        {
          role: 'system',
          content: 'ä½ æ˜¯æµ‹è¯•æŠ¥å‘Šä¸“å®¶ã€‚'
        },
        {
          role: 'user',
          content: `${promptTemplate}\n\n${JSON.stringify(results, null, 2)}`
        }
      ],
      max_tokens: 4000
    });

    return completion.choices[0].message.content;
  }
}

// ============================================
// Google Gemini æœåŠ¡å®žçŽ°
// ============================================
class GeminiService extends BaseAIService {
  constructor(config) {
    super(config);
    this.baseURL = this.baseURL || 'https://generativelanguage.googleapis.com/v1beta';
    this.model = this.model || 'gemini-pro';
  }

  async makeRequest(prompt) {
    const response = await fetch(
      `${this.baseURL}/models/${this.model}:generateContent?key=${this.apiKey}`,
      {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [{
            parts: [{ text: prompt }]
          }]
        })
      }
    );

    const data = await response.json();
    return data.candidates[0].content.parts[0].text;
  }

  async analyze(testConfig, promptTemplate) {
    const prompt = this.fillTemplate(promptTemplate, testConfig);
    const content = await this.makeRequest(prompt);
    return this.parseJSON(content);
  }

  async generateTestCases(analysis, promptTemplate) {
    const prompt = `${promptTemplate}\n\n${JSON.stringify(analysis, null, 2)}`;
    const content = await this.makeRequest(prompt);
    return this.parseJSON(content);
  }

  async generateReport(results, promptTemplate) {
    const prompt = `${promptTemplate}\n\n${JSON.stringify(results, null, 2)}`;
    return await this.makeRequest(prompt);
  }
}

// ============================================
// é˜¿é‡Œé€šä¹‰åƒé—® æœåŠ¡å®žçŽ°
// ============================================
class QwenService extends BaseAIService {
  constructor(config) {
    super(config);
    this.baseURL = this.baseURL || 'https://dashscope.aliyuncs.com/api/v1';
    this.model = this.model || 'qwen-max';
  }

  async makeRequest(messages) {
    const response = await fetch(
      `${this.baseURL}/services/aigc/text-generation/generation`,
      {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${this.apiKey}`
        },
        body: JSON.stringify({
          model: this.model,
          input: { messages },
          parameters: {
            max_tokens: 4000,
            temperature: 0.7
          }
        })
      }
    );

    const data = await response.json();
    return data.output.text;
  }

  async analyze(testConfig, promptTemplate) {
    const prompt = this.fillTemplate(promptTemplate, testConfig);
    const content = await this.makeRequest([
      { role: 'system', content: 'ä½ æ˜¯ä¸“ä¸šçš„æµ‹è¯•å·¥ç¨‹å¸ˆã€‚' },
      { role: 'user', content: prompt }
    ]);
    return this.parseJSON(content);
  }

  async generateTestCases(analysis, promptTemplate) {
    const content = await this.makeRequest([
      { role: 'system', content: 'ä½ æ˜¯æµ‹è¯•ç”¨ä¾‹è®¾è®¡ä¸“å®¶ã€‚' },
      { role: 'user', content: `${promptTemplate}\n\n${JSON.stringify(analysis, null, 2)}` }
    ]);
    return this.parseJSON(content);
  }

  async generateReport(results, promptTemplate) {
    return await this.makeRequest([
      { role: 'system', content: 'ä½ æ˜¯æµ‹è¯•æŠ¥å‘Šä¸“å®¶ã€‚' },
      { role: 'user', content: `${promptTemplate}\n\n${JSON.stringify(results, null, 2)}` }
    ]);
  }
}

// ============================================
// æ™ºè°± GLM æœåŠ¡å®žçŽ°
// ============================================
class GLMService extends BaseAIService {
  constructor(config) {
    super(config);
    this.baseURL = this.baseURL || 'https://open.bigmodel.cn/api/paas/v4';
    this.model = this.model || 'glm-4';
  }

  async makeRequest(messages) {
    const response = await fetch(`${this.baseURL}/chat/completions`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${this.apiKey}`
      },
      body: JSON.stringify({
        model: this.model,
        messages,
        max_tokens: 4000
      })
    });

    const data = await response.json();
    return data.choices[0].message.content;
  }

  async analyze(testConfig, promptTemplate) {
    const prompt = this.fillTemplate(promptTemplate, testConfig);
    const content = await this.makeRequest([
      { role: 'system', content: 'ä½ æ˜¯ä¸“ä¸šçš„æµ‹è¯•å·¥ç¨‹å¸ˆã€‚' },
      { role: 'user', content: prompt }
    ]);
    return this.parseJSON(content);
  }

  async generateTestCases(analysis, promptTemplate) {
    const content = await this.makeRequest([
      { role: 'system', content: 'ä½ æ˜¯æµ‹è¯•ç”¨ä¾‹è®¾è®¡ä¸“å®¶ã€‚' },
      { role: 'user', content: `${promptTemplate}\n\n${JSON.stringify(analysis, null, 2)}` }
    ]);
    return this.parseJSON(content);
  }

  async generateReport(results, promptTemplate) {
    return await this.makeRequest([
      { role: 'system', content: 'ä½ æ˜¯æµ‹è¯•æŠ¥å‘Šä¸“å®¶ã€‚' },
      { role: 'user', content: `${promptTemplate}\n\n${JSON.stringify(results, null, 2)}` }
    ]);
  }
}

// ============================================
// ä½¿ç”¨ç¤ºä¾‹
// ============================================

// é…ç½®æ–‡ä»¶ç¤ºä¾‹
const aiConfigs = {
  claude: {
    provider: 'claude',
    apiKey: 'sk-ant-...',
    model: 'claude-sonnet-4-20250514'
  },
  deepseek: {
    provider: 'deepseek',
    apiKey: 'sk-...',
    baseURL: 'https://api.deepseek.com/v1',
    model: 'deepseek-chat'
  },
  openai: {
    provider: 'openai',
    apiKey: 'sk-...',
    model: 'gpt-4-turbo'
  },
  gemini: {
    provider: 'gemini',
    apiKey: 'AIza...',
    model: 'gemini-pro'
  },
  qwen: {
    provider: 'qwen',
    apiKey: 'sk-...',
    model: 'qwen-max'
  },
  glm: {
    provider: 'glm',
    apiKey: 'sk-...',
    model: 'glm-4'
  }
};

// ä¸»æœåŠ¡ç±» - é›†æˆAIæœåŠ¡
class AutoTestService {
  constructor(aiProvider = 'claude') {
    this.aiProvider = aiProvider;
    this.aiService = null;
  }

  // åˆå§‹åŒ–AIæœåŠ¡
  async init(config) {
    this.aiService = AIServiceFactory.create(this.aiProvider, config);
  }

  // åˆ‡æ¢AIæä¾›å•†
  switchAI(provider, config) {
    this.aiProvider = provider;
    this.aiService = AIServiceFactory.create(provider, config);
  }

  // æ‰§è¡Œå®Œæ•´çš„è‡ªåŠ¨åŒ–æµ‹è¯•æµç¨‹
  async runAutoTest(testConfig, prompts) {
    if (!this.aiService) {
      throw new Error('AIæœåŠ¡æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè°ƒç”¨ init() æ–¹æ³•');
    }

    const results = {
      provider: this.aiProvider,
      timestamp: new Date().toISOString(),
      steps: []
    };

    try {
      // æ­¥éª¤1: é¡µé¢åˆ†æž
      console.log('ðŸ” æ­£åœ¨åˆ†æžé¡µé¢...');
      results.analysis = await this.aiService.analyze(testConfig, prompts.analysis);
      results.steps.push('é¡µé¢åˆ†æžå®Œæˆ');

      // æ­¥éª¤2: ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹
      console.log('ðŸ“‹ æ­£åœ¨ç”Ÿæˆæµ‹è¯•ç”¨ä¾‹...');
      results.testCases = await this.aiService.generateTestCases(
        results.analysis,
        prompts.testCase
      );
      results.steps.push('æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆå®Œæˆ');

      // æ­¥éª¤3: è¿™é‡Œå¯ä»¥æ‰§è¡Œå®žé™…æµ‹è¯•ï¼ˆä½¿ç”¨Puppeteerï¼‰
      // const testResults = await executeTests(results.testCases);

      // æ­¥éª¤4: ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
      console.log('ðŸ“Š æ­£åœ¨ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š...');
      results.report = await this.aiService.generateReport(
        results.testCases,
        prompts.report
      );
      results.steps.push('æµ‹è¯•æŠ¥å‘Šç”Ÿæˆå®Œæˆ');

      return results;

    } catch (error) {
      console.error('è‡ªåŠ¨åŒ–æµ‹è¯•å¤±è´¥:', error);
      results.error = error.message;
      return results;
    }
  }
}

// ============================================
// Express æœåŠ¡å™¨é›†æˆç¤ºä¾‹
// ============================================

const express = require('express');
const app = express();
app.use(express.json());

// å…¨å±€AIæœåŠ¡å®žä¾‹
let autoTestService = new AutoTestService('claude');

// API: åˆå§‹åŒ–AIæœåŠ¡
app.post('/api/ai/init', async (req, res) => {
  const { provider, config } = req.body;

  try {
    autoTestService = new AutoTestService(provider);
    await autoTestService.init(config);

    res.json({
      success: true,
      message: `å·²åˆ‡æ¢åˆ° ${provider}`,
      provider
    });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

// API: èŽ·å–æ”¯æŒçš„AIæä¾›å•†åˆ—è¡¨
app.get('/api/ai/providers', (req, res) => {
  res.json({
    providers: [
      { id: 'claude', name: 'Claude (Anthropic)', recommended: true },
      { id: 'deepseek', name: 'DeepSeek', recommended: true },
      { id: 'openai', name: 'OpenAI (GPT)', recommended: false },
      { id: 'gemini', name: 'Google Gemini', recommended: false },
      { id: 'qwen', name: 'é˜¿é‡Œé€šä¹‰åƒé—®', recommended: false },
      { id: 'glm', name: 'æ™ºè°± GLM', recommended: false }
    ]
  });
});

// API: æ‰§è¡Œè‡ªåŠ¨åŒ–æµ‹è¯•
app.post('/api/auto-test', async (req, res) => {
  const { config, prompts } = req.body;

  try {
    const results = await autoTestService.runAutoTest(config, prompts);
    res.json(results);
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

module.exports = {
  AIServiceFactory,
  BaseAIService,
  ClaudeService,
  DeepSeekService,
  OpenAIService,
  GeminiService,
  QwenService,
  GLMService,
  AutoTestService
};